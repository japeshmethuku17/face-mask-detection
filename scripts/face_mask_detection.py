# -*- coding: utf-8 -*-
"""japesh_face_mask_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FQ3PnLQDnt58iKptAl1Gd6zJ5Md5f2PZ

# **Compiled by: Japesh Methuku**
LinkedIn Profile: [Japesh Methuku](https://www.linkedin.com/in/japeshmethuku/)

## **Import required libraries**
"""

# %tensorflow_version 2.x

# import tensorflow and tensorflow.keras
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import backend as K

# import ImageDataGenerator and the related functions required for processing images
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D

# import optimizers
from tensorflow.keras.optimizers import SGD, Adam, Adagrad, Adadelta, RMSprop

# import statements for building and loading the model
from tensorflow.keras import models
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.models import model_from_json

# import statements for callbacks
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping

# import statements for initlializers and regularizers
from tensorflow.keras.initializers import glorot_uniform
from tensorflow.keras.regularizers import l2

# import statements for loading ResNet50 from keras
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input

# import statements for scikit-learn
import sklearn.metrics as metrics

# import os for file access
import os 

# import numpy, pandas
import numpy as np
import pandas as pd

# import opencv
import cv2

# import matplotlib
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

# import zipfile for unzipping the data
import zipfile

# import csv to access the csv files
import csv

# import drive to access the data from GDrive
from google.colab import drive

# import seaborn
import seaborn as sns

# import time
from time import time
print("tensorflow version:",tf.__version__)

"""## **Loading images from the dataset**"""

# Mounting the drive to the Colab Notebook for accessing the data
drive.mount('/content/drive/', force_remount=True)

# Unzipping the folder conatining the images and data
image_data = zipfile.ZipFile("/content/drive/My Drive/face_mask_detection.zip", 'r')
image_data.extractall("/tmp")
image_data.close()

# Specifying the location of training images after extraction
training_dir = '/tmp/face_mask_detection/train/'
testing_dir = '/tmp/face_mask_detection/test'

# Loading the csv file to access the details of the images
training_data = pd.read_csv('/tmp/face_mask_detection/Training_set_face_mask.csv', na_values='na')
testing_data = pd.read_csv('/tmp/face_mask_detection/Testing_set_face_mask.csv')

# Displaying top 10 values of the csv file
training_data.head(10)

train_datagen = ImageDataGenerator(validation_split=0.2)
valid_datagen = ImageDataGenerator(validation_split=0.2)
train_data = train_datagen.flow_from_directory(training_dir, class_mode='categorical', target_size=(224,224), subset='training', batch_size=32)
valid_data = valid_datagen.flow_from_directory(training_dir, class_mode='categorical', target_size=(224,224), subset='validation', batch_size=32,shuffle=False)

"""## **Model Creation**"""

# Loading the ResNet50 model
resnet_base = ResNet50(weights= 'imagenet', include_top=False, input_shape= (224,224,3))
resnet_base.summary()

# Sequential building of the image classification model
# Using Keras Sequential API
model = models.Sequential()
model.add(resnet_base)
model.add(keras.layers.GlobalAveragePooling2D())
model.add(keras.layers.Dense(2, activation = 'softmax'))

# Visualizing the summary of the model
model.summary()

"""## **Model Compilation**"""

# Using Stochastic Gradient Descent as optimization algorithm
OPTIMIZER = keras.optimizers.SGD(lr=0.0001)
model.compile(loss='categorical_crossentropy',
              optimizer = OPTIMIZER,
              metrics=['accuracy'])

# Specifying the callbacks
callbacks_list= [keras.callbacks.ModelCheckpoint('Face_Mask_Model.hdf5', 
                                                 monitor='val_accuracy', 
                                                 verbose=1, 
                                                 save_best_only=True)]

"""## **Train Model**"""

# Fit the compiled model on the training data and validate with validation data
history= model.fit(train_data, steps_per_epoch= 11264//32, 
                    callbacks=callbacks_list, 
                    epochs = 50, verbose = 1, validation_data = valid_data)

"""## **Visualize the execution results**"""

# Visualize accuracy results
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Training and Validation Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.minorticks_on()
plt.grid()
plt.figure()
# save image
plt.savefig('Classification Model Accuracy', dpi=250)
plt.show()

# Visualize loss results
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Training and Validation Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.minorticks_on()
plt.grid()
plt.figure()
# save image
plt.savefig('Classification Model Loss', dpi=250)
plt.show()

"""## **Load Model for Predictions**"""

final_model = load_model('/content/drive/My Drive/Challenges/Submission/Face_Mask_Model.hdf5')
print("Model is loaded")

# Display the validation accuracy and loss
results = final_model.evaluate(valid_data)
print("Loss: ", results[0])
print("Accuracy: ", results[1])

testing_data.head(5)

img_details = testing_data['filename']
print(len(img_details))
print(img_details[2])

test_pred = []
for j in range(0,len(img_details)):
  img_name = testing_dir+"/"+img_details[j]
  # reading the images
  #print(img_name)
  img = cv2.imread(img_name)
  # Converting the color space from BGR to RGB
  img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB)
  # resizing the images to size required by ResNet50
  img = cv2.resize(img, (224,224))
  img = img.reshape(-1,224,224,3)
  prediction = final_model.predict(img)
  test_pred.append(np.argmax(prediction))

print(len(test_pred))

res = pd.DataFrame(test_pred)
res.columns=["prediction"]
res.to_csv("pred_results.csv")
from google.colab import files     
files.download('pred_results.csv')