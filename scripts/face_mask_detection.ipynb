{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0z2lBAtqUGV"
   },
   "source": [
    "# **Compiled by: Japesh Methuku**\n",
    "LinkedIn Profile: [Japesh Methuku](https://www.linkedin.com/in/japeshmethuku/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eiaz0AaZYOvy"
   },
   "source": [
    "## **Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DIFrz3nsI4Jq",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 2.x\n",
    "\n",
    "# import tensorflow and tensorflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# import ImageDataGenerator and the related functions required for processing images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "\n",
    "# import optimizers\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adagrad, Adadelta, RMSprop\n",
    "\n",
    "# import statements for building and loading the model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# import statements for callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# import statements for initlializers and regularizers\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# import statements for loading ResNet50 from keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# import statements for scikit-learn\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# import os for file access\n",
    "import os \n",
    "\n",
    "# import numpy, pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import opencv\n",
    "import cv2\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "# import zipfile for unzipping the data\n",
    "import zipfile\n",
    "\n",
    "# import csv to access the csv files\n",
    "import csv\n",
    "\n",
    "# import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# import time\n",
    "from time import time\n",
    "print(\"tensorflow version:\",tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rr3U6CvWfYWU"
   },
   "source": [
    "## **Loading images from the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WuywS4xNJWB7"
   },
   "outputs": [],
   "source": [
    "# Specifying the location of training images after extraction\n",
    "training_dir = '../train/'\n",
    "testing_dir = './test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L220b60AqCV-"
   },
   "outputs": [],
   "source": [
    "# Loading the csv file to access the details of the images\n",
    "training_data = pd.read_csv('../Training_set_face_mask.csv', na_values='na')\n",
    "testing_data = pd.read_csv('../Testing_set_face_mask.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "b2Cx4L-sqXr9",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Image_6.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Image_7.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Image_8.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Image_9.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Image_10.jpg</td>\n",
       "      <td>without_mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename         label\n",
       "0   Image_1.jpg  without_mask\n",
       "1   Image_2.jpg  without_mask\n",
       "2   Image_3.jpg  without_mask\n",
       "3   Image_4.jpg  without_mask\n",
       "4   Image_5.jpg  without_mask\n",
       "5   Image_6.jpg  without_mask\n",
       "6   Image_7.jpg  without_mask\n",
       "7   Image_8.jpg  without_mask\n",
       "8   Image_9.jpg  without_mask\n",
       "9  Image_10.jpg  without_mask"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying top 10 values of the csv file\n",
    "training_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0F3hcFJGndxE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9012 images belonging to 2 classes.\n",
      "Found 2252 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(validation_split=0.2)\n",
    "train_data = datagen.flow_from_directory(training_dir, class_mode='categorical', target_size=(224,224), subset='training', batch_size=32)\n",
    "valid_data = datagen.flow_from_directory(training_dir, class_mode='categorical', target_size=(224,224), subset='validation', batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwJxgbhvo8fX"
   },
   "source": [
    "## **Model Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAkVahz2XGrM"
   },
   "outputs": [],
   "source": [
    "# Loading the ResNet50 model\n",
    "resnet_base = ResNet50(weights= 'imagenet', include_top=False, input_shape= (224,224,3))\n",
    "resnet_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0Pz3XI2tVXGz"
   },
   "outputs": [],
   "source": [
    "# Sequential building of the image classification model\n",
    "# Using Keras Sequential API\n",
    "model = models.Sequential()\n",
    "model.add(resnet_base)\n",
    "model.add(keras.layers.GlobalAveragePooling2D())\n",
    "model.add(keras.layers.Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4zWDk1VhoDo"
   },
   "outputs": [],
   "source": [
    "# Visualizing the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYDBQMVXqCPJ"
   },
   "source": [
    "## **Model Compilation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RBvdodjWYpQk"
   },
   "outputs": [],
   "source": [
    "# Using Stochastic Gradient Descent as optimization algorithm\n",
    "OPTIMIZER = keras.optimizers.SGD(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = OPTIMIZER,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DaBc3IFzY4ep"
   },
   "outputs": [],
   "source": [
    "# Specifying the callbacks\n",
    "callbacks_list= [keras.callbacks.ModelCheckpoint('Face_Mask_Model.hdf5', \n",
    "                                                 monitor='val_accuracy', \n",
    "                                                 verbose=1, \n",
    "                                                 save_best_only=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-X1HbGbsuPZY"
   },
   "source": [
    "## **Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zL1nF4EcZ-lS"
   },
   "outputs": [],
   "source": [
    "# Fit the compiled model on the training data and validate with validation data\n",
    "history= model.fit(train_data, steps_per_epoch= 11264//32, \n",
    "                    callbacks=callbacks_list, \n",
    "                    epochs = 50, verbose = 1, validation_data = valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGVu5q6rvmEk"
   },
   "source": [
    "## **Visualize the execution results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atp_oi3rfny9"
   },
   "outputs": [],
   "source": [
    "# Visualize accuracy results\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.minorticks_on()\n",
    "plt.grid()\n",
    "plt.figure()\n",
    "# save image\n",
    "plt.savefig('Classification Model Accuracy', dpi=250)\n",
    "plt.show()\n",
    "\n",
    "# Visualize loss results\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.minorticks_on()\n",
    "plt.grid()\n",
    "plt.figure()\n",
    "# save image\n",
    "plt.savefig('Classification Model Loss', dpi=250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzRXcrWDlPHH"
   },
   "source": [
    "## **Load Model for Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-M1oq74o1M2"
   },
   "outputs": [],
   "source": [
    "final_model = load_model('Face_Mask_Model.hdf5')\n",
    "print(\"Model is loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mn9_Trcs7UDB"
   },
   "outputs": [],
   "source": [
    "# Display the validation accuracy and loss\n",
    "results = final_model.evaluate(valid_data)\n",
    "print(\"Loss: \", results[0])\n",
    "print(\"Accuracy: \", results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QN4I5YNI9yxG"
   },
   "outputs": [],
   "source": [
    "testing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNY6pFQg-Qn2"
   },
   "outputs": [],
   "source": [
    "img_details = testing_data['filename']\n",
    "print(len(img_details))\n",
    "print(img_details[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "x2tc3lkj4iw3"
   },
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "for j in range(0,len(img_details)):\n",
    "  img_name = testing_dir+\"/\"+img_details[j]\n",
    "  # reading the images\n",
    "  #print(img_name)\n",
    "  img = cv2.imread(img_name)\n",
    "  # Converting the color space from BGR to RGB\n",
    "  img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB)\n",
    "  # resizing the images to size required by ResNet50\n",
    "  img = cv2.resize(img, (224,224))\n",
    "  img = img.reshape(-1,224,224,3)\n",
    "  prediction = final_model.predict(img)\n",
    "  test_pred.append(np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imcK1x0apCqz"
   },
   "outputs": [],
   "source": [
    "print(len(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iiJF4Hf7pFqh"
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(test_pred)\n",
    "res.columns=[\"prediction\"]\n",
    "res.to_csv(\"pred_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze> requirements.txt"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "japesh_face_mask_detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
