{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "japesh_face_mask_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0z2lBAtqUGV"
      },
      "source": [
        "# **Compiled by: Japesh Methuku**\n",
        "LinkedIn Profile: [Japesh Methuku](https://www.linkedin.com/in/japeshmethuku/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eiaz0AaZYOvy"
      },
      "source": [
        "## **Import required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIFrz3nsI4Jq"
      },
      "source": [
        "# %tensorflow_version 2.x\n",
        "\n",
        "# import tensorflow and tensorflow.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# import ImageDataGenerator and the related functions required for processing images\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "\n",
        "# import optimizers\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adagrad, Adadelta, RMSprop\n",
        "\n",
        "# import statements for building and loading the model\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "# import statements for callbacks\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# import statements for initlializers and regularizers\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# import statements for loading ResNet50 from keras\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# import statements for scikit-learn\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "# import os for file access\n",
        "import os \n",
        "\n",
        "# import numpy, pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# import opencv\n",
        "import cv2\n",
        "\n",
        "# import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "# import zipfile for unzipping the data\n",
        "import zipfile\n",
        "\n",
        "# import csv to access the csv files\n",
        "import csv\n",
        "\n",
        "# import drive to access the data from GDrive\n",
        "from google.colab import drive\n",
        "\n",
        "# import seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "# import time\n",
        "from time import time\n",
        "print(\"tensorflow version:\",tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr3U6CvWfYWU"
      },
      "source": [
        "## **Loading images from the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZrkZaJo9OBe"
      },
      "source": [
        "# Mounting the drive to the Colab Notebook for accessing the data\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV3CPBkpJVLw"
      },
      "source": [
        "# Unzipping the folder conatining the images and data\n",
        "image_data = zipfile.ZipFile(\"/content/drive/My Drive/face_mask_detection.zip\", 'r')\n",
        "image_data.extractall(\"/tmp\")\n",
        "image_data.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuywS4xNJWB7"
      },
      "source": [
        "# Specifying the location of training images after extraction\n",
        "training_dir = '/tmp/face_mask_detection/train/'\n",
        "testing_dir = '/tmp/face_mask_detection/test'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L220b60AqCV-"
      },
      "source": [
        "# Loading the csv file to access the details of the images\n",
        "training_data = pd.read_csv('/tmp/face_mask_detection/Training_set_face_mask.csv', na_values='na')\n",
        "testing_data = pd.read_csv('/tmp/face_mask_detection/Testing_set_face_mask.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2Cx4L-sqXr9"
      },
      "source": [
        "# Displaying top 10 values of the csv file\n",
        "training_data.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F3hcFJGndxE"
      },
      "source": [
        "train_datagen = ImageDataGenerator(validation_split=0.2)\n",
        "valid_datagen = ImageDataGenerator(validation_split=0.2)\n",
        "train_data = train_datagen.flow_from_directory(training_dir, class_mode='categorical', target_size=(224,224), subset='training', batch_size=32)\n",
        "valid_data = valid_datagen.flow_from_directory(training_dir, class_mode='categorical', target_size=(224,224), subset='validation', batch_size=32,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwJxgbhvo8fX"
      },
      "source": [
        "## **Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAkVahz2XGrM"
      },
      "source": [
        "# Loading the ResNet50 model\n",
        "resnet_base = ResNet50(weights= 'imagenet', include_top=False, input_shape= (224,224,3))\n",
        "resnet_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pz3XI2tVXGz"
      },
      "source": [
        "# Sequential building of the image classification model\n",
        "# Using Keras Sequential API\n",
        "model = models.Sequential()\n",
        "model.add(resnet_base)\n",
        "model.add(keras.layers.GlobalAveragePooling2D())\n",
        "model.add(keras.layers.Dense(2, activation = 'softmax'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4zWDk1VhoDo"
      },
      "source": [
        "# Visualizing the summary of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYDBQMVXqCPJ"
      },
      "source": [
        "## **Model Compilation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBvdodjWYpQk"
      },
      "source": [
        "# Using Stochastic Gradient Descent as optimization algorithm\n",
        "OPTIMIZER = keras.optimizers.SGD(lr=0.0001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = OPTIMIZER,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaBc3IFzY4ep"
      },
      "source": [
        "# Specifying the callbacks\n",
        "callbacks_list= [keras.callbacks.ModelCheckpoint('Face_Mask_Model.hdf5', \n",
        "                                                 monitor='val_accuracy', \n",
        "                                                 verbose=1, \n",
        "                                                 save_best_only=True)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X1HbGbsuPZY"
      },
      "source": [
        "## **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL1nF4EcZ-lS"
      },
      "source": [
        "# Fit the compiled model on the training data and validate with validation data\n",
        "history= model.fit(train_data, steps_per_epoch= 11264//32, \n",
        "                    callbacks=callbacks_list, \n",
        "                    epochs = 50, verbose = 1, validation_data = valid_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGVu5q6rvmEk"
      },
      "source": [
        "## **Visualize the execution results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atp_oi3rfny9"
      },
      "source": [
        "# Visualize accuracy results\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.minorticks_on()\n",
        "plt.grid()\n",
        "plt.figure()\n",
        "# save image\n",
        "plt.savefig('Classification Model Accuracy', dpi=250)\n",
        "plt.show()\n",
        "\n",
        "# Visualize loss results\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.minorticks_on()\n",
        "plt.grid()\n",
        "plt.figure()\n",
        "# save image\n",
        "plt.savefig('Classification Model Loss', dpi=250)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzRXcrWDlPHH"
      },
      "source": [
        "## **Load Model for Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-M1oq74o1M2"
      },
      "source": [
        "final_model = load_model('/content/drive/My Drive/Challenges/Submission/Face_Mask_Model.hdf5')\n",
        "print(\"Model is loaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn9_Trcs7UDB"
      },
      "source": [
        "# Display the validation accuracy and loss\n",
        "results = final_model.evaluate(valid_data)\n",
        "print(\"Loss: \", results[0])\n",
        "print(\"Accuracy: \", results[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN4I5YNI9yxG"
      },
      "source": [
        "testing_data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNY6pFQg-Qn2"
      },
      "source": [
        "img_details = testing_data['filename']\n",
        "print(len(img_details))\n",
        "print(img_details[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2tc3lkj4iw3"
      },
      "source": [
        "test_pred = []\n",
        "for j in range(0,len(img_details)):\n",
        "  img_name = testing_dir+\"/\"+img_details[j]\n",
        "  # reading the images\n",
        "  #print(img_name)\n",
        "  img = cv2.imread(img_name)\n",
        "  # Converting the color space from BGR to RGB\n",
        "  img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB)\n",
        "  # resizing the images to size required by ResNet50\n",
        "  img = cv2.resize(img, (224,224))\n",
        "  img = img.reshape(-1,224,224,3)\n",
        "  prediction = final_model.predict(img)\n",
        "  test_pred.append(np.argmax(prediction))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imcK1x0apCqz"
      },
      "source": [
        "print(len(test_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiJF4Hf7pFqh"
      },
      "source": [
        "res = pd.DataFrame(test_pred)\n",
        "res.columns=[\"prediction\"]\n",
        "res.to_csv(\"pred_results.csv\")\n",
        "from google.colab import files     \n",
        "files.download('pred_results.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}